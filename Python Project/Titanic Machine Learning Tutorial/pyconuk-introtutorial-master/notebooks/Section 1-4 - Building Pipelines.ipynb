{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1-4 - Building Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV reviews the performance of a set range of parameters on a cross-validation basis. This means only a portion of the training data is reviewed at any one time. When filling in the NA values with the mean value, however, we considered the whole set of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we took an inconsistent approach in reviewing only a portion of the data when running GridSearchCV, but the full set of data when filling in missing values. We can avoid this inconsistency by building pipelines and making imputations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td>                           Braund, Mr. Owen Harris</td>\n",
       "      <td>   male</td>\n",
       "      <td> 22</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> A/5 21171</td>\n",
       "      <td>  7.2500</td>\n",
       "      <td> NaN</td>\n",
       "      <td> S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td> female</td>\n",
       "      <td> 38</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>  PC 17599</td>\n",
       "      <td> 71.2833</td>\n",
       "      <td> C85</td>\n",
       "      <td> C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S'], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Embarked'].isnull()]\n",
    "df['Embarked'].dropna().mode().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't work because no Prefix column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_means_prefix = df.pivot_table('Age', index='Prefix', aggfunc='mean')\n",
    "\n",
    "df[ (df['Name'].str.contains('Mr.') | df['Name'].str.contains('Miss') | df['Name'].str.contains('Ms')) \n",
    "   & df['Age'].isnull()].head()\n",
    "\n",
    "#fill age based on Prefix\n",
    "df['Age'] = df[['Age', 'Prefix']].apply(lambda x:\n",
    "                            age_means_prefix[x['Prefix']] if pd.isnull(x['Age'])\n",
    "                            else x['Age'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 3</td>\n",
       "      <td> 22</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>  7.2500</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 2</td>\n",
       "      <td> 1</td>\n",
       "      <td> 38</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 71.2833</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  PassengerId  Pclass  Age  SibSp  Parch     Fare  Gender  \\\n",
       "0         0            1       3   22      1      0   7.2500       1   \n",
       "1         1            2       1   38      1      0  71.2833       0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Replace missing values with most common port\n",
    "df['Embarked'].isnull= df['Embarked'].dropna().mode().values\n",
    "\n",
    "#mode_embarked = mode(df['Embarked'])[0][0]\n",
    "#df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace the NA values in the column Age with a negative value marker -1, as the following bug disallows us from using a missing value marker:\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/3044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then review our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived       891 non-null int64\n",
      "PassengerId    891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "Gender         891 non-null int32\n",
      "Embarked_C     891 non-null float64\n",
      "Embarked_Q     891 non-null float64\n",
      "Embarked_S     891 non-null float64\n",
      "dtypes: float64(5), int32(1), int64(5)\n",
      "memory usage: 80.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>   0.383838</td>\n",
       "      <td> 446.000000</td>\n",
       "      <td>   2.308642</td>\n",
       "      <td>  23.600640</td>\n",
       "      <td>   0.523008</td>\n",
       "      <td>   0.381594</td>\n",
       "      <td>  32.204208</td>\n",
       "      <td>   0.647587</td>\n",
       "      <td>   0.188552</td>\n",
       "      <td>   0.086420</td>\n",
       "      <td>   0.722783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>   0.486592</td>\n",
       "      <td> 257.353842</td>\n",
       "      <td>   0.836071</td>\n",
       "      <td>  17.867496</td>\n",
       "      <td>   1.102743</td>\n",
       "      <td>   0.806057</td>\n",
       "      <td>  49.693429</td>\n",
       "      <td>   0.477990</td>\n",
       "      <td>   0.391372</td>\n",
       "      <td>   0.281141</td>\n",
       "      <td>   0.447876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>  -1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>   0.000000</td>\n",
       "      <td> 223.500000</td>\n",
       "      <td>   2.000000</td>\n",
       "      <td>   6.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   7.910400</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>   0.000000</td>\n",
       "      <td> 446.000000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td>  24.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>  14.454200</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>   1.000000</td>\n",
       "      <td> 668.500000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td>  35.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>  31.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   0.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>   1.000000</td>\n",
       "      <td> 891.000000</td>\n",
       "      <td>   3.000000</td>\n",
       "      <td>  80.000000</td>\n",
       "      <td>   8.000000</td>\n",
       "      <td>   6.000000</td>\n",
       "      <td> 512.329200</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838   446.000000    2.308642   23.600640    0.523008   \n",
       "std      0.486592   257.353842    0.836071   17.867496    1.102743   \n",
       "min      0.000000     1.000000    1.000000   -1.000000    0.000000   \n",
       "25%      0.000000   223.500000    2.000000    6.000000    0.000000   \n",
       "50%      0.000000   446.000000    3.000000   24.000000    0.000000   \n",
       "75%      1.000000   668.500000    3.000000   35.000000    1.000000   \n",
       "max      1.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare      Gender  Embarked_C  Embarked_Q  Embarked_S  \n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
       "mean     0.381594   32.204208    0.647587    0.188552    0.086420    0.722783  \n",
       "std      0.806057   49.693429    0.477990    0.391372    0.281141    0.447876  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    7.910400    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000   14.454200    1.000000    0.000000    0.000000    1.000000  \n",
       "75%      0.000000   31.000000    1.000000    0.000000    0.000000    1.000000  \n",
       "max      6.000000  512.329200    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    1.,    3., ...,    0.,    0.,    1.],\n",
       "       [   1.,    2.,    1., ...,    1.,    0.,    0.],\n",
       "       [   1.,    3.,    3., ...,    0.,    0.,    1.],\n",
       "       ..., \n",
       "       [   0.,  889.,    3., ...,    0.,    0.,    1.],\n",
       "       [   1.,  890.,    1., ...,    1.,    0.,    0.],\n",
       "       [   0.,  891.,    3., ...,    0.,    1.,    0.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df.values\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a pipeline to enable us to first impute the mean value of the column Age on the portion of the training data we are considering, and second, assess the performance of our tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "imputer = Imputer(strategy='mean', missing_values=-1)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imp', imputer),\n",
    "    ('clf', classifier),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note the slight change made to the syntax inside our parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'clf__max_features': [0.5, 1],\n",
    "    'clf__max_depth': [5, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run GridSearchCV as before but replacing the classifier with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameter_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,  22.,   1., ...,   0.,   0.,   1.],\n",
       "       [  1.,  38.,   1., ...,   1.,   0.,   0.],\n",
       "       [  3.,  26.,   0., ...,   0.,   0.,   1.],\n",
       "       ..., \n",
       "       [  3.,  -1.,   1., ...,   0.,   0.,   1.],\n",
       "       [  1.,  26.,   0., ...,   1.,   0.,   0.],\n",
       "       [  3.,  32.,   0., ...,   0.,   1.,   0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] clf__max_depth=5, clf__max_features=0.5 .........................\n",
      "[CV]  clf__max_depth=5, clf__max_features=0.5, score=0.804469 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=0.5 .........................\n",
      "[CV]  clf__max_depth=5, clf__max_features=0.5, score=0.826816 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=0.5 .........................\n",
      "[CV]  clf__max_depth=5, clf__max_features=0.5, score=0.837079 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=0.5 .........................\n",
      "[CV]  clf__max_depth=5, clf__max_features=0.5, score=0.786517 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=0.5 .........................\n",
      "[CV]  clf__max_depth=5, clf__max_features=0.5, score=0.858757 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=1 ...........................\n",
      "[CV] .. clf__max_depth=5, clf__max_features=1, score=0.776536 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=1 ...........................\n",
      "[CV] .. clf__max_depth=5, clf__max_features=1, score=0.821229 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=1 ...........................\n",
      "[CV] .. clf__max_depth=5, clf__max_features=1, score=0.853933 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=1 ...........................\n",
      "[CV] .. clf__max_depth=5, clf__max_features=1, score=0.803371 -   0.0s\n",
      "[CV] clf__max_depth=5, clf__max_features=1 ...........................\n",
      "[CV] .. clf__max_depth=5, clf__max_features=1, score=0.858757 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=0.5 ......................\n",
      "[CV]  clf__max_depth=None, clf__max_features=0.5, score=0.793296 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=0.5 ......................\n",
      "[CV]  clf__max_depth=None, clf__max_features=0.5, score=0.821229 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=0.5 ......................\n",
      "[CV]  clf__max_depth=None, clf__max_features=0.5, score=0.853933 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=0.5 ......................\n",
      "[CV]  clf__max_depth=None, clf__max_features=0.5, score=0.775281 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=0.5 ......................\n",
      "[CV]  clf__max_depth=None, clf__max_features=0.5, score=0.841808 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=1 ........................\n",
      "[CV]  clf__max_depth=None, clf__max_features=1, score=0.776536 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=1 ........................\n",
      "[CV]  clf__max_depth=None, clf__max_features=1, score=0.798883 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=1 ........................\n",
      "[CV]  clf__max_depth=None, clf__max_features=1, score=0.848315 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=1 ........................\n",
      "[CV]  clf__max_depth=None, clf__max_features=1, score=0.792135 -   0.0s\n",
      "[CV] clf__max_depth=None, clf__max_features=1 ........................\n",
      "[CV]  clf__max_depth=None, clf__max_features=1, score=0.830508 -   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "       estimator=Pipeline(steps=[('imp', Imputer(axis=0, copy=True, missing_values=-1, strategy='mean', verbose=0)), ('clf', RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0))]),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'clf__max_depth': [5, None], 'clf__max_features': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_data[0:,2:], train_data[0:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 5, 'clf__max_features': 0.5}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.grid_scores_, key=lambda x: x.mean_validation_score)\n",
    "grid_search.best_score_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've determined the desired values for our tuning parameters, we can fill in the -1 values in the column Age with the mean and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      23.600640\n",
       "std       17.867496\n",
       "min       -1.000000\n",
       "25%        6.000000\n",
       "50%       24.000000\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].map(lambda x: age_mean if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.699118\n",
       "std       13.002015\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       29.699118\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, max_features=0.5, max_depth=5)\n",
    "model = model.fit(train_data[0:,2:],train_data[0:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill in the NA values in test data with the mean, since there is no analogous problem of snooping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['Age'] = df_test['Age'].fillna(age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uf425c\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\index.py:648: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n",
      "  type(self).__name__),FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "test_data = df_test.values\n",
    "\n",
    "output = model.predict(test_data[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('../results/titanic_1-4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
